{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTVfq_As3uxE"
      },
      "source": [
        "**Vijay Panchal - 7225949**\n",
        "\n",
        "This project outlines RNN and how it works in the case to make a model which predicts the next word based on the dataset. Utilizing tensorflow, we are able to effectively preprocess the data, train the model, and test the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXI39_htPDF-"
      },
      "outputs": [],
      "source": [
        "with open('Data.txt', 'r', encoding='utf-8') as file:\n",
        "    textData = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1pIWkyyy_1q"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H3rHJZi9q6w"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Cleans up the whitespace, special characters, and fixes extra whitespaces and periods. It makes sure that each sequence will end on a period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7ZPHWr4SIms"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def cleanText(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Keep only letters and whitespace and period\n",
        "    text = re.sub(r'[^a-z.\\s]', '', text)\n",
        "\n",
        "    # Replace multiple spaces/newlines with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd7tGS0Y-KkT"
      },
      "source": [
        "## Split Into Sentences\n",
        "\n",
        "Using the delimiter, we split text using period and classify as a sentence. We strip the sentences that are empty to make sure we don't classify them as sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI0F0ru-mEJb"
      },
      "outputs": [],
      "source": [
        "def splitIntoSentences(cleanedText, delimiter='.'):\n",
        "    sentences = cleanedText.split(delimiter)\n",
        "    # strip whitespace and remove empties\n",
        "    sentences = [s.strip() for s in sentences if s.strip() != '']\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SjX5U9MAEzM"
      },
      "source": [
        "## Build and Tokenize\n",
        "\n",
        "Find every unique word and build vocabulary or words. This process allows us to convert all words in the book to certain int ids. Each sentence is made up of a sequence of ints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KktkZbSjtvq3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def buildAndTokenize(listOfSentences):\n",
        "    t = Tokenizer()\n",
        "    t.fit_on_texts(listOfSentences)\n",
        "    tokenizedSentences = t.texts_to_sequences(listOfSentences)\n",
        "\n",
        "    return t, tokenizedSentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-4ffbddDPBi"
      },
      "source": [
        "## Pad Sequences\n",
        "\n",
        "Using max length which is determined before calling this method, we know what size we want to either truncate or padd each of the sequences. In this case, we are using the largest possible sequence length so we do not need to truncate anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iIkEh7zm0qn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def padTokenizedSequences(tokenizedSentences, maxLength, padding='pre', truncating='pre'):\n",
        "    padded = pad_sequences(tokenizedSentences, maxlen=maxLength, padding=padding, truncating=truncating)\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zl6cRwoGcHn"
      },
      "source": [
        "## Running the Data Preprocessing methods\n",
        "\n",
        "1. First *Clean Up* the text\n",
        "2. Then we make a list of sentences by splitting everytime there is a period\n",
        "3. *Build and Tokenize* each sentence.\n",
        "4. Determine the maxLength of the sequence so it can be used to padd\n",
        "5. *Padd* each sentence/sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRfp320nBjn",
        "outputId": "9c96e7a7-64eb-4220-9ec1-50384fe1c345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 6434\n",
            "101\n"
          ]
        }
      ],
      "source": [
        "cleanedText = cleanText(textData)\n",
        "listOfSentences = cleanedText.split('.')\n",
        "print(\"Number of sentences:\", len(listOfSentences))\n",
        "\n",
        "t, tokenizedSentences = buildAndTokenize(listOfSentences)\n",
        "\n",
        "maxLength = max(len(s) for s in tokenizedSentences)\n",
        "print(maxLength)\n",
        "paddedSentences = padTokenizedSequences(tokenizedSentences, maxLength)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGuF8isaJJKh"
      },
      "source": [
        "# Building and Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PcHC5zVNaj8"
      },
      "source": [
        "## Creating The Unique Word Dictionary\n",
        "Creates a dictionary to map each unique word to an index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRDxUFRL7VnG",
        "outputId": "09cbb85e-798a-4648-b32f-e0f803d5b8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8599\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "vocabSize = len(t.word_index) + 1\n",
        "\n",
        "print(vocabSize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVHwxvtORTOM"
      },
      "source": [
        "## Building the Model\n",
        "\n",
        "1. *Embedding Dimension* allows each word to be represented in 200 different contexts.\n",
        "2. *LSTM* are hidden units which allows us capture different sequence patterns between words.\n",
        "3. *Dense* allows us to have a probability distribution which over every possible word in the vocabulary. We use the softmax to classify which word has a higher probability based on the text.\n",
        "4. Using all these classifications, we build the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "f9C_qvXHJdwp",
        "outputId": "29540a0c-e548-4e50-b44b-21cde3a82719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,719,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">168,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8599</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,109,271</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m1,719,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m168,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8599\u001b[0m)                │       \u001b[38;5;34m1,109,271\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,519</span> (11.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,997,519\u001b[0m (11.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,519</span> (11.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,997,519\u001b[0m (11.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "embeddingDim = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabSize, output_dim=embeddingDim, input_length=(maxLength-1)))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(vocabSize, activation='softmax'))\n",
        "model.build(input_shape=(None, maxLength - 1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xWD5xkTDso"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ_24BnpXAuz"
      },
      "source": [
        "## Compile The Model\n",
        "1. *Adaptive Moment Estimation* is the optimizer we used which utilizes the ideas of adaptive learning rates and bias correction. This overall allows the program to progress more efficiently.\n",
        "2. *Cross Entrophy* tells us how close our predicted probabilities are to the true probability.\n",
        "3. We use the accurary metrix to help us determine if we are progressing correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni9koDIjR1C8"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEV4LDM6Z_wX"
      },
      "source": [
        "- X takes in all columns except the output features.\n",
        "- y takes the last column of as the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7liMCT8_TKTb"
      },
      "outputs": [],
      "source": [
        "X = paddedSentences[:, :-1]\n",
        "y = paddedSentences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocabSize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGFkj5k4aaca"
      },
      "source": [
        "## Train The Model\n",
        "1. I did 30 epochs as the model accuracy improved the most drastically after 10 epochs until 25. 30 Epochs was done just incase it improved more.\n",
        "2. Validation split is 10% as it retains 10% of the training data as a validation set. This allows us to reduce the chances of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PngHerOKYmFU",
        "outputId": "9d0fc480-7ee4-4370-cc07-19470b65dca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 311ms/step - accuracy: 0.0301 - loss: 8.4999 - val_accuracy: 0.0543 - val_loss: 8.1660\n",
            "Epoch 2/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 319ms/step - accuracy: 0.0386 - loss: 6.9669 - val_accuracy: 0.0543 - val_loss: 8.4580\n",
            "Epoch 3/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 309ms/step - accuracy: 0.0436 - loss: 6.7249 - val_accuracy: 0.0543 - val_loss: 8.5072\n",
            "Epoch 4/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.0465 - loss: 6.5862 - val_accuracy: 0.0528 - val_loss: 8.6343\n",
            "Epoch 5/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 309ms/step - accuracy: 0.0476 - loss: 6.5506 - val_accuracy: 0.0435 - val_loss: 8.8131\n",
            "Epoch 6/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.0498 - loss: 6.3970 - val_accuracy: 0.0450 - val_loss: 8.7570\n",
            "Epoch 7/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 309ms/step - accuracy: 0.0610 - loss: 6.2249 - val_accuracy: 0.0466 - val_loss: 8.7999\n",
            "Epoch 8/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.0729 - loss: 6.0621 - val_accuracy: 0.0528 - val_loss: 8.7767\n",
            "Epoch 9/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 326ms/step - accuracy: 0.0798 - loss: 5.8421 - val_accuracy: 0.0575 - val_loss: 8.7675\n",
            "Epoch 10/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 316ms/step - accuracy: 0.0925 - loss: 5.6011 - val_accuracy: 0.0575 - val_loss: 8.7975\n",
            "Epoch 11/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 309ms/step - accuracy: 0.0981 - loss: 5.4286 - val_accuracy: 0.0528 - val_loss: 8.8934\n",
            "Epoch 12/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.1090 - loss: 5.2591 - val_accuracy: 0.0543 - val_loss: 8.9570\n",
            "Epoch 13/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 309ms/step - accuracy: 0.1234 - loss: 5.0436 - val_accuracy: 0.0590 - val_loss: 8.9161\n",
            "Epoch 14/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 304ms/step - accuracy: 0.1281 - loss: 4.8920 - val_accuracy: 0.0559 - val_loss: 9.0911\n",
            "Epoch 15/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.1473 - loss: 4.6901 - val_accuracy: 0.0606 - val_loss: 9.0618\n",
            "Epoch 16/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 304ms/step - accuracy: 0.1539 - loss: 4.5484 - val_accuracy: 0.0575 - val_loss: 9.1153\n",
            "Epoch 17/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 333ms/step - accuracy: 0.1687 - loss: 4.3800 - val_accuracy: 0.0575 - val_loss: 9.1691\n",
            "Epoch 18/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 312ms/step - accuracy: 0.1983 - loss: 4.1861 - val_accuracy: 0.0559 - val_loss: 9.2154\n",
            "Epoch 19/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 313ms/step - accuracy: 0.2156 - loss: 4.0440 - val_accuracy: 0.0606 - val_loss: 9.2757\n",
            "Epoch 20/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 320ms/step - accuracy: 0.2475 - loss: 3.8744 - val_accuracy: 0.0590 - val_loss: 9.3162\n",
            "Epoch 21/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 308ms/step - accuracy: 0.2848 - loss: 3.7326 - val_accuracy: 0.0652 - val_loss: 9.4101\n",
            "Epoch 22/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 309ms/step - accuracy: 0.3128 - loss: 3.5554 - val_accuracy: 0.0606 - val_loss: 9.4691\n",
            "Epoch 23/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - accuracy: 0.3561 - loss: 3.3959 - val_accuracy: 0.0637 - val_loss: 9.5159\n",
            "Epoch 24/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 309ms/step - accuracy: 0.3875 - loss: 3.2643 - val_accuracy: 0.0606 - val_loss: 9.5510\n",
            "Epoch 25/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.4285 - loss: 3.1108 - val_accuracy: 0.0621 - val_loss: 9.6356\n",
            "Epoch 26/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 320ms/step - accuracy: 0.4802 - loss: 2.9257 - val_accuracy: 0.0621 - val_loss: 9.6669\n",
            "Epoch 27/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 311ms/step - accuracy: 0.5104 - loss: 2.8099 - val_accuracy: 0.0606 - val_loss: 9.7292\n",
            "Epoch 28/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 313ms/step - accuracy: 0.5414 - loss: 2.6337 - val_accuracy: 0.0590 - val_loss: 9.8017\n",
            "Epoch 29/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 313ms/step - accuracy: 0.5763 - loss: 2.5509 - val_accuracy: 0.0621 - val_loss: 9.8447\n",
            "Epoch 30/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 310ms/step - accuracy: 0.5968 - loss: 2.4103 - val_accuracy: 0.0575 - val_loss: 9.9173\n",
            "Epoch 31/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 321ms/step - accuracy: 0.6269 - loss: 2.3018 - val_accuracy: 0.0606 - val_loss: 9.9707\n",
            "Epoch 32/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 309ms/step - accuracy: 0.6434 - loss: 2.1845 - val_accuracy: 0.0590 - val_loss: 10.0060\n",
            "Epoch 33/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 310ms/step - accuracy: 0.6749 - loss: 2.0564 - val_accuracy: 0.0590 - val_loss: 10.0416\n",
            "Epoch 34/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.6794 - loss: 1.9681 - val_accuracy: 0.0606 - val_loss: 10.0821\n",
            "Epoch 35/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 340ms/step - accuracy: 0.7043 - loss: 1.8593 - val_accuracy: 0.0559 - val_loss: 10.1446\n",
            "Epoch 36/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 318ms/step - accuracy: 0.7192 - loss: 1.7711 - val_accuracy: 0.0575 - val_loss: 10.2056\n",
            "Epoch 37/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.7382 - loss: 1.6570 - val_accuracy: 0.0575 - val_loss: 10.2269\n",
            "Epoch 38/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 311ms/step - accuracy: 0.7425 - loss: 1.5882 - val_accuracy: 0.0559 - val_loss: 10.2596\n",
            "Epoch 39/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 309ms/step - accuracy: 0.7614 - loss: 1.4909 - val_accuracy: 0.0543 - val_loss: 10.3281\n",
            "Epoch 40/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.7921 - loss: 1.3771 - val_accuracy: 0.0543 - val_loss: 10.3834\n",
            "Epoch 41/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.7813 - loss: 1.3566 - val_accuracy: 0.0543 - val_loss: 10.4335\n",
            "Epoch 42/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.8031 - loss: 1.2549 - val_accuracy: 0.0559 - val_loss: 10.4684\n",
            "Epoch 43/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 304ms/step - accuracy: 0.8044 - loss: 1.2139 - val_accuracy: 0.0543 - val_loss: 10.5160\n",
            "Epoch 44/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 314ms/step - accuracy: 0.8301 - loss: 1.1268 - val_accuracy: 0.0559 - val_loss: 10.5527\n",
            "Epoch 45/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 306ms/step - accuracy: 0.8295 - loss: 1.0744 - val_accuracy: 0.0590 - val_loss: 10.5549\n",
            "Epoch 46/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.8392 - loss: 1.0219 - val_accuracy: 0.0512 - val_loss: 10.6034\n",
            "Epoch 47/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - accuracy: 0.8455 - loss: 0.9707 - val_accuracy: 0.0575 - val_loss: 10.6210\n",
            "Epoch 48/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - accuracy: 0.8550 - loss: 0.9413 - val_accuracy: 0.0590 - val_loss: 10.6341\n",
            "Epoch 49/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - accuracy: 0.8603 - loss: 0.9001 - val_accuracy: 0.0543 - val_loss: 10.6868\n",
            "Epoch 50/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 301ms/step - accuracy: 0.8673 - loss: 0.8478 - val_accuracy: 0.0575 - val_loss: 10.7332\n",
            "Epoch 51/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 305ms/step - accuracy: 0.8746 - loss: 0.7892 - val_accuracy: 0.0543 - val_loss: 10.7421\n",
            "Epoch 52/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.8746 - loss: 0.7852 - val_accuracy: 0.0543 - val_loss: 10.7848\n",
            "Epoch 53/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 321ms/step - accuracy: 0.8845 - loss: 0.7381 - val_accuracy: 0.0512 - val_loss: 10.8163\n",
            "Epoch 54/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 321ms/step - accuracy: 0.8969 - loss: 0.6732 - val_accuracy: 0.0575 - val_loss: 10.8400\n",
            "Epoch 55/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 303ms/step - accuracy: 0.8915 - loss: 0.6762 - val_accuracy: 0.0512 - val_loss: 10.8631\n",
            "Epoch 56/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 304ms/step - accuracy: 0.8996 - loss: 0.6476 - val_accuracy: 0.0606 - val_loss: 10.8865\n",
            "Epoch 57/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 308ms/step - accuracy: 0.9027 - loss: 0.6243 - val_accuracy: 0.0528 - val_loss: 10.9259\n",
            "Epoch 58/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 303ms/step - accuracy: 0.9035 - loss: 0.6139 - val_accuracy: 0.0559 - val_loss: 10.9208\n",
            "Epoch 59/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - accuracy: 0.9133 - loss: 0.5976 - val_accuracy: 0.0543 - val_loss: 10.9702\n",
            "Epoch 60/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 330ms/step - accuracy: 0.9120 - loss: 0.5686 - val_accuracy: 0.0621 - val_loss: 10.9810\n",
            "Epoch 61/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 307ms/step - accuracy: 0.9203 - loss: 0.5314 - val_accuracy: 0.0559 - val_loss: 11.0202\n",
            "Epoch 62/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 316ms/step - accuracy: 0.9221 - loss: 0.4951 - val_accuracy: 0.0606 - val_loss: 11.0352\n",
            "Epoch 63/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 308ms/step - accuracy: 0.9209 - loss: 0.4889 - val_accuracy: 0.0543 - val_loss: 11.0702\n",
            "Epoch 64/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - accuracy: 0.9221 - loss: 0.4765 - val_accuracy: 0.0621 - val_loss: 11.1382\n",
            "Epoch 65/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 303ms/step - accuracy: 0.9282 - loss: 0.4517 - val_accuracy: 0.0606 - val_loss: 11.1047\n",
            "Epoch 66/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 307ms/step - accuracy: 0.9311 - loss: 0.4439 - val_accuracy: 0.0590 - val_loss: 11.1444\n",
            "Epoch 67/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 309ms/step - accuracy: 0.9296 - loss: 0.4236 - val_accuracy: 0.0606 - val_loss: 11.1730\n",
            "Epoch 68/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - accuracy: 0.9355 - loss: 0.4053 - val_accuracy: 0.0559 - val_loss: 11.2052\n",
            "Epoch 69/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - accuracy: 0.9458 - loss: 0.3717 - val_accuracy: 0.0543 - val_loss: 11.2111\n",
            "Epoch 70/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - accuracy: 0.9396 - loss: 0.3851 - val_accuracy: 0.0606 - val_loss: 11.2543\n",
            "Epoch 71/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 319ms/step - accuracy: 0.9427 - loss: 0.3551 - val_accuracy: 0.0543 - val_loss: 11.2546\n",
            "Epoch 72/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.9405 - loss: 0.3760 - val_accuracy: 0.0621 - val_loss: 11.2785\n",
            "Epoch 73/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 302ms/step - accuracy: 0.9435 - loss: 0.3437 - val_accuracy: 0.0590 - val_loss: 11.3096\n",
            "Epoch 74/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 306ms/step - accuracy: 0.9481 - loss: 0.3350 - val_accuracy: 0.0543 - val_loss: 11.3367\n",
            "Epoch 75/75\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.9499 - loss: 0.3262 - val_accuracy: 0.0373 - val_loss: 11.3207\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X, y, batch_size = 64, epochs=30, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqk_gDXYbKej"
      },
      "source": [
        "# Test The Next Word Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu07JnadeiXw"
      },
      "source": [
        "## Creating the Predict Next Word Method\n",
        "\n",
        "1. Preprocess the user input.\n",
        "2. Load in the token list into the Model and use it to predict the probability distribution over the vocabulary.\n",
        "3. Find the index of the highest probability.\n",
        "4. Convert the index into the actual word which is found in the word index and return that word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvzximMii7vb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_next_word(model, tokenizer, userText, maxLength):\n",
        "    # 1.\n",
        "    tokenList = tokenizer.texts_to_sequences([userText])[0]\n",
        "\n",
        "    tokenList = pad_sequences([tokenList], maxlen=maxLength - 1, padding='pre')\n",
        "\n",
        "    #2.\n",
        "    predictedProbs = model.predict(tokenList, verbose=0)[0]\n",
        "\n",
        "    #3.\n",
        "    predictedIndex = np.argmax(predictedProbs)\n",
        "\n",
        "    #4.\n",
        "    nextWord = None\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "        if idx == predictedIndex:\n",
        "            nextWord = word\n",
        "            break\n",
        "\n",
        "    return nextWord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bg951WwdWda"
      },
      "source": [
        "## Running The Program\n",
        "\n",
        "Does a while true loop which takes in the user input(A sentence that the user wants to complete), shows the next predicted word, and the option to continue predicting words until you want to quit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAfojQFR2T5a",
        "outputId": "681640b6-0068-4e9e-9b1a-a8bf63d833a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a partial sentence (or 'quit'): I am \n",
            "Next word might be: armed\n",
            "Enter a partial sentence (or 'quit'): by train from\n",
            "Next word might be: waterloo\n",
            "Enter a partial sentence (or 'quit'): I would have endured\n",
            "Next word might be: means\n",
            "Enter a partial sentence (or 'quit'): quit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    userInput = input(\"Enter a partial sentence (or 'quit'): \")\n",
        "    if userInput.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    resultWord = predict_next_word(model, t, userInput, maxLength)\n",
        "    if resultWord:\n",
        "        print(\"Next word might be:\", resultWord)\n",
        "    else:\n",
        "        print(\"Could not predict a next word.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icwNJh_PfRjx"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this project we created a RNN Model to predict which word comes after the inputted sentence. Firstly, we started by preprocessing the data.txt file. Then, we built the RNN model utilizing tensorflow's method. Then, after continous tweaking and grasphing the hyperparamters like embedded dimension, optimization model, etc, we were able to train our model to be above 90% accuracy. This accurate model was used in creating a program that can predict the next word in the dataset aka the book \"The Adventures of Sherlock Holmes,\" by Arthur Conan Doyle."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMehcy0aGNkJxGV3AawzYWl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}